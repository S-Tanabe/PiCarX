<!DOCTYPE html>
<html lang="ja">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>VR Stereo Viewer + Controller (LiveKit + WebXR + MQTT)</title>
    <style>
      * { margin: 0; padding: 0; }
      body {
        background: #000;
        color: #fff;
        font-family: system-ui, sans-serif;
        overflow: hidden;
      }
      #ui {
        position: absolute;
        top: 20px;
        left: 20px;
        z-index: 100;
        display: flex;
        flex-direction: column;
        gap: 10px;
      }
      button {
        padding: 15px 30px;
        font-size: 18px;
        border: none;
        border-radius: 8px;
        cursor: pointer;
        background: #4a90d9;
        color: #fff;
      }
      button:hover { background: #3a7bc8; }
      button:disabled { background: #555; cursor: not-allowed; }
      #status {
        padding: 10px;
        background: rgba(0,0,0,0.7);
        border-radius: 8px;
        font-size: 14px;
      }
      #preview {
        position: absolute;
        bottom: 20px;
        right: 20px;
        width: 320px;
        background: #111;
        border: 1px solid #333;
        border-radius: 8px;
      }
      #canvas {
        width: 100%;
        height: 100%;
        display: block;
      }
      .config {
        background: rgba(0,0,0,0.7);
        padding: 10px;
        border-radius: 8px;
        font-size: 14px;
      }
      .config input {
        background: #222;
        border: 1px solid #444;
        color: #fff;
        padding: 5px 8px;
        border-radius: 4px;
        width: 200px;
      }
      .config label {
        display: block;
        margin: 5px 0;
      }
      #controlInfo {
        position: absolute;
        bottom: 20px;
        left: 20px;
        background: rgba(0,0,0,0.8);
        padding: 10px;
        border-radius: 8px;
        font-size: 12px;
        max-width: 300px;
      }
      .media-controls {
        display: flex;
        gap: 8px;
      }
      .media-controls button {
        padding: 10px 15px;
        font-size: 14px;
      }
      .media-controls button.active {
        background: #2ecc71;
      }
      .media-controls button.active:hover {
        background: #27ae60;
      }
      #localPreview {
        position: absolute;
        top: 20px;
        right: 20px;
        width: 160px;
        height: 120px;
        background: #111;
        border: 2px solid #4a90d9;
        border-radius: 8px;
        object-fit: cover;
      }
      /* Audio Mixer Panel */
      #mixerPanel {
        position: absolute;
        bottom: 20px;
        right: 350px;
        background: rgba(20, 20, 30, 0.95);
        border: 1px solid #444;
        border-radius: 10px;
        padding: 15px;
        min-width: 200px;
      }
      #mixerPanel h3 {
        margin: 0 0 12px 0;
        font-size: 14px;
        color: #aaa;
        border-bottom: 1px solid #333;
        padding-bottom: 8px;
      }
      .mixer-channel {
        display: flex;
        align-items: center;
        gap: 10px;
        margin: 8px 0;
        padding: 6px 0;
      }
      .mixer-channel .label {
        width: 70px;
        font-size: 11px;
        color: #888;
      }
      .mixer-channel .meter-container {
        flex: 1;
        height: 12px;
        background: #1a1a2a;
        border-radius: 6px;
        overflow: hidden;
        position: relative;
      }
      .mixer-channel .meter-bar {
        height: 100%;
        width: 0%;
        border-radius: 6px;
        transition: width 0.05s ease-out;
      }
      .mixer-channel .meter-bar.input {
        background: linear-gradient(90deg, #2ecc71 0%, #f1c40f 70%, #e74c3c 100%);
      }
      .mixer-channel .meter-bar.output {
        background: linear-gradient(90deg, #3498db 0%, #9b59b6 70%, #e74c3c 100%);
      }
      .mixer-channel .level-text {
        width: 45px;
        font-size: 10px;
        color: #666;
        text-align: right;
        font-family: monospace;
      }
      .mixer-section {
        margin-top: 10px;
        padding-top: 10px;
        border-top: 1px solid #333;
      }
      .mixer-section-title {
        font-size: 11px;
        color: #666;
        margin-bottom: 6px;
      }
      .status-dot {
        width: 8px;
        height: 8px;
        border-radius: 50%;
        background: #555;
      }
      .status-dot.active {
        background: #2ecc71;
        box-shadow: 0 0 6px #2ecc71;
      }
    </style>
  </head>
  <body>
    <div id="ui">
      <button id="connectBtn">Connect (LiveKit + MQTT)</button>
      <button id="vrBtn" disabled>Enter VR</button>
      <button id="previewBtn" disabled>Preview Stereo (Non-VR)</button>
      <div class="media-controls">
        <button id="cameraBtn" disabled>Camera OFF</button>
        <button id="micBtn" disabled>Mic OFF</button>
      </div>
      <div id="status">Status: Disconnected</div>
      <div class="config">
        <label>MQTT URL: <input id="mqttUrl" value="wss://relay.yuru-yuru.net/mqtt" /></label>
        <label>Topic: <input id="topicBase" value="demo/picarx" /></label>
      </div>
    </div>
    <video id="preview" autoplay playsinline muted></video>
    <video id="localPreview" autoplay playsinline muted style="display:none;"></video>
    <audio id="remoteAudio" autoplay></audio>
    <canvas id="canvas"></canvas>

    <!-- Audio Mixer Panel -->
    <div id="mixerPanel">
      <h3>Audio Mixer</h3>
      <div class="mixer-section">
        <div class="mixer-section-title">Local (Input)</div>
        <div class="mixer-channel">
          <div class="status-dot" id="micStatusDot"></div>
          <div class="label">Mic In</div>
          <div class="meter-container">
            <div class="meter-bar input" id="micLevelBar"></div>
          </div>
          <div class="level-text" id="micLevelText">-∞ dB</div>
        </div>
      </div>
      <div class="mixer-section">
        <div class="mixer-section-title">Remote (Output)</div>
        <div class="mixer-channel">
          <div class="status-dot" id="remoteAudioStatusDot"></div>
          <div class="label">Audio Out</div>
          <div class="meter-container">
            <div class="meter-bar output" id="remoteAudioLevelBar"></div>
          </div>
          <div class="level-text" id="remoteAudioLevelText">-∞ dB</div>
        </div>
      </div>
    </div>
    <div id="controlInfo">
      <strong>VR Controller:</strong><br>
      Left Stick: Drive (Y: Forward/Back, X: Steer)<br>
      Right Stick: Camera (X: Pan, Y: Tilt)<br>
      Any Trigger: Stop
    </div>

    <!-- LiveKit SDK -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/livekit-client/2.15.7/livekit-client.umd.js"></script>

    <!-- MQTT SDK -->
    <script src="https://unpkg.com/mqtt/dist/mqtt.min.js"></script>

    <!-- Three.js for WebXR -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>

    <script>
      // ====== 設定 ======
      const wsUrl = 'wss://relay.yuru-yuru.net';
      const token = 'eyJhbGciOiJIUzI1NiJ9.eyJ2aWRlbyI6eyJyb29tSm9pbiI6dHJ1ZSwicm9vbSI6InZyLWRlbW8iLCJjYW5QdWJsaXNoIjp0cnVlLCJjYW5TdWJzY3JpYmUiOnRydWUsImNhblB1Ymxpc2hEYXRhIjp0cnVlfSwiaXNzIjoiTEtfQVBJX0tFWSIsImV4cCI6MTc2OTY5OTU3NywibmJmIjowLCJzdWIiOiJ2ci1oZWFkc2V0In0.-HZYX0BR6VAtwZLbsh0G6vwJOgyNEFNpNslLgV5OaMM'; // 双方向通信用 30日 (2026-01-30)
      // ==================

      const connectBtn = document.getElementById('connectBtn');
      const vrBtn = document.getElementById('vrBtn');
      const previewBtn = document.getElementById('previewBtn');
      const cameraBtn = document.getElementById('cameraBtn');
      const micBtn = document.getElementById('micBtn');
      const statusEl = document.getElementById('status');
      const preview = document.getElementById('preview');
      const localPreview = document.getElementById('localPreview');
      const remoteAudio = document.getElementById('remoteAudio');
      const canvas = document.getElementById('canvas');
      const mqttUrlEl = document.getElementById('mqttUrl');
      const topicBaseEl = document.getElementById('topicBase');

      // Mixer elements
      const micLevelBar = document.getElementById('micLevelBar');
      const micLevelText = document.getElementById('micLevelText');
      const micStatusDot = document.getElementById('micStatusDot');
      const remoteAudioLevelBar = document.getElementById('remoteAudioLevelBar');
      const remoteAudioLevelText = document.getElementById('remoteAudioLevelText');
      const remoteAudioStatusDot = document.getElementById('remoteAudioStatusDot');

      let room = null;
      let localVideoTrack = null;
      let localAudioTrack = null;
      let cameraEnabled = false;
      let micEnabled = false;
      let videoElement = null;

      // Audio analysis
      let audioContext = null;
      let micAnalyser = null;
      let remoteAnalyser = null;
      let micStream = null;
      let remoteAudioTrack = null;
      let renderer, scene, cameraL, cameraR, camera;
      let xrSession = null;
      let videoTexture = null;
      let previewMode = false;
      let mqttClient = null;
      let vrMode = false;
      let vrModeType = null; // 'layers'
      let xrReferenceSpace = null;
      let xrMediaBinding = null;
      let xrQuadLayer = null;
      let xrProjectionLayer = null;
      let xrGlContext = null;
      let stereoMeshL = null;
      let stereoMeshR = null;

      // コントローラー状態
      let lastThrottle = 0;
      let lastSteer = 0;
      let currentPan = 0;   // カメラパン角度 (-90~90)
      let currentTilt = 0;  // カメラチルト角度 (-35~65)
      const DEADZONE = 0.15;
      const SEND_INTERVAL = 100; // ms
      let lastSendTime = 0;
      let lastCameraSendTime = 0;

      function setStatus(msg) {
        statusEl.innerHTML = msg;
        console.log(msg.replace(/<br>/g, ' | '));
      }

      // ====== Audio Level Metering ======
      function initAudioContext() {
        if (!audioContext) {
          audioContext = new (window.AudioContext || window.webkitAudioContext)();
        }
        return audioContext;
      }

      function setupMicAnalyser(stream) {
        const ctx = initAudioContext();
        micAnalyser = ctx.createAnalyser();
        micAnalyser.fftSize = 256;
        const source = ctx.createMediaStreamSource(stream);
        source.connect(micAnalyser);
        micStream = stream;
        micStatusDot.classList.add('active');
        startMicMeter();
      }

      function setupRemoteAudioAnalyser(audioElement) {
        const ctx = initAudioContext();
        remoteAnalyser = ctx.createAnalyser();
        remoteAnalyser.fftSize = 256;
        try {
          const source = ctx.createMediaElementSource(audioElement);
          source.connect(remoteAnalyser);
          remoteAnalyser.connect(ctx.destination);
          remoteAudioStatusDot.classList.add('active');
          startRemoteAudioMeter();
        } catch (e) {
          console.warn('Remote audio analyser setup failed:', e);
        }
      }

      function getAudioLevel(analyser) {
        if (!analyser) return 0;
        const data = new Uint8Array(analyser.frequencyBinCount);
        analyser.getByteFrequencyData(data);
        let sum = 0;
        for (let i = 0; i < data.length; i++) {
          sum += data[i];
        }
        return sum / data.length / 255; // 0-1
      }

      function levelToDb(level) {
        if (level <= 0) return -Infinity;
        return 20 * Math.log10(level);
      }

      function updateMeter(levelBar, levelText, level) {
        const percent = Math.min(100, Math.max(0, level * 100));
        levelBar.style.width = percent + '%';
        const db = levelToDb(level);
        if (db === -Infinity) {
          levelText.textContent = '-∞ dB';
        } else {
          levelText.textContent = db.toFixed(1) + ' dB';
        }
      }

      let micMeterInterval = null;
      function startMicMeter() {
        if (micMeterInterval) return;
        micMeterInterval = setInterval(() => {
          const level = getAudioLevel(micAnalyser);
          updateMeter(micLevelBar, micLevelText, level);
        }, 50);
      }

      function stopMicMeter() {
        if (micMeterInterval) {
          clearInterval(micMeterInterval);
          micMeterInterval = null;
        }
        micStatusDot.classList.remove('active');
        updateMeter(micLevelBar, micLevelText, 0);
      }

      let remoteMeterInterval = null;
      function startRemoteAudioMeter() {
        if (remoteMeterInterval) return;
        remoteMeterInterval = setInterval(() => {
          const level = getAudioLevel(remoteAnalyser);
          updateMeter(remoteAudioLevelBar, remoteAudioLevelText, level);
        }, 50);
      }

      function stopRemoteAudioMeter() {
        if (remoteMeterInterval) {
          clearInterval(remoteMeterInterval);
          remoteMeterInterval = null;
        }
        remoteAudioStatusDot.classList.remove('active');
        updateMeter(remoteAudioLevelBar, remoteAudioLevelText, 0);
      }

      // ====== Attach Remote Audio ======
      function attachRemoteAudioTrack(track) {
        console.log('Attaching remote audio track');
        remoteAudioTrack = track;
        const audioEl = track.attach();
        audioEl.id = 'remoteAudioElement';
        remoteAudio.srcObject = audioEl.srcObject;
        remoteAudio.play().catch(e => console.warn('Remote audio autoplay blocked:', e));

        // Setup analyser after a short delay to ensure audio is playing
        setTimeout(() => {
          if (remoteAudio.srcObject) {
            try {
              const ctx = initAudioContext();
              remoteAnalyser = ctx.createAnalyser();
              remoteAnalyser.fftSize = 256;
              const source = ctx.createMediaStreamSource(remoteAudio.srcObject);
              source.connect(remoteAnalyser);
              remoteAudioStatusDot.classList.add('active');
              startRemoteAudioMeter();
            } catch (e) {
              console.warn('Remote audio analyser error:', e);
            }
          }
        }, 500);
      }

      // MQTT接続
      function connectMqtt() {
        return new Promise((resolve, reject) => {
          const url = mqttUrlEl.value.trim();
          if (!/^wss?:\/\//.test(url)) {
            reject(new Error('MQTT URL must start with ws:// or wss://'));
            return;
          }

          if (mqttClient) {
            mqttClient.end(true);
            mqttClient = null;
          }

          const timeoutId = setTimeout(() => {
            reject(new Error('MQTT connection timeout'));
          }, 10000);

          mqttClient = mqtt.connect(url, {
            keepalive: 30,
            reconnectPeriod: 2000,
          });

          mqttClient.on('connect', () => {
            clearTimeout(timeoutId);
            console.log('MQTT connected');
            resolve();
          });

          mqttClient.on('error', (e) => {
            clearTimeout(timeoutId);
            reject(new Error('MQTT error: ' + e.message));
          });

          mqttClient.on('reconnect', () => console.log('MQTT reconnecting...'));
          mqttClient.on('close', () => console.log('MQTT disconnected'));
        });
      }

      // MQTT送信
      function publishMqtt(subtopic, payload) {
        if (!mqttClient || !mqttClient.connected) {
          return;
        }
        const base = topicBaseEl.value.trim() || 'demo/picarx';
        const topic = `${base}/${subtopic}`;
        const msg = JSON.stringify(payload);
        mqttClient.publish(topic, msg, { qos: 0, retain: false });
      }

      // 走行コマンド送信
      function sendDrive(throttle, steer) {
        publishMqtt('cmd', { throttle, steer });
      }

      // カメラパン/チルト送信
      function sendCamera(pan, tilt) {
        publishMqtt('camera', { pan, tilt });
      }

      function attachVideoTrack(track) {
        const hidden = track.attach();
        hidden.style.position = 'fixed';
        hidden.style.left = '-10000px';
        hidden.style.top = '0px';
        hidden.style.width = '2px';
        hidden.style.height = '2px';
        hidden.style.opacity = '0';
        hidden.style.pointerEvents = 'none';
        hidden.playsInline = true;
        hidden.muted = true;
        document.body.appendChild(hidden);

        const previewVideo = track.attach();
        previewVideo.playsInline = true;
        previewVideo.muted = true;
        preview.srcObject = previewVideo.srcObject;

        videoElement = hidden;
        videoElement.play().catch(() => {});
        preview.play().catch(() => {});

        vrBtn.disabled = false;
        previewBtn.disabled = false;
      }

      async function waitForVideoReady(video, timeoutMs = 6000) {
        const start = performance.now();
        while (true) {
          if (
            video.readyState >= HTMLMediaElement.HAVE_CURRENT_DATA &&
            video.videoWidth > 0 &&
            video.videoHeight > 0
          ) {
            return true;
          }
          if (performance.now() - start > timeoutMs) {
            return false;
          }
          await new Promise(resolve => setTimeout(resolve, 100));
        }
      }

      // LiveKit接続
      async function connectLiveKit() {
        room = new LivekitClient.Room({
          adaptiveStream: true,
          dynacast: true,
        });

        room.on(LivekitClient.RoomEvent.TrackSubscribed, (track, publication, participant) => {
          console.log(`Track subscribed: ${track.kind} from ${participant.identity}`);
          if (track.kind === 'video') {
            attachVideoTrack(track);
          } else if (track.kind === 'audio') {
            attachRemoteAudioTrack(track);
          }
        });

        room.on(LivekitClient.RoomEvent.TrackUnsubscribed, (track, publication, participant) => {
          console.log(`Track unsubscribed: ${track.kind} from ${participant.identity}`);
          if (track.kind === 'audio') {
            stopRemoteAudioMeter();
            remoteAudioTrack = null;
          }
        });

        room.on(LivekitClient.RoomEvent.Disconnected, async () => {
          setStatus('Status: Disconnected');
          vrBtn.disabled = true;
          previewBtn.disabled = true;
          connectBtn.disabled = false;
          vrMode = false;
          vrModeType = null;
          cleanupLayers();
          if (xrSession) {
            try {
              await xrSession.end();
            } catch (_) {}
            xrSession = null;
          }
        });

        await room.connect(wsUrl, token);

        // 既存の参加者のトラックを購読
        room.remoteParticipants.forEach(p => {
          p.trackPublications.forEach(pub => {
            if (pub.isSubscribed && pub.track) {
              if (pub.track.kind === 'video') {
                attachVideoTrack(pub.track);
              } else if (pub.track.kind === 'audio') {
                attachRemoteAudioTrack(pub.track);
              }
            }
          });
        });

        return room.name;
      }

      // 統合接続
      async function connect() {
        connectBtn.disabled = true;
        setStatus('Status: Connecting...');

        try {
          const [roomName] = await Promise.all([
            connectLiveKit(),
            connectMqtt()
          ]);
          setStatus(`Status: Connected<br>Room: ${roomName}<br>MQTT: OK`);
          // カメラ・マイクボタンを有効化
          cameraBtn.disabled = false;
          micBtn.disabled = false;
        } catch (e) {
          setStatus('Status: Error - ' + e.message);
          connectBtn.disabled = false;
          if (room) {
            await room.disconnect();
            room = null;
          }
          if (mqttClient) {
            mqttClient.end(true);
            mqttClient = null;
          }
        }
      }

      // Three.js + WebXR セットアップ
      function initThreeJS() {
        renderer = new THREE.WebGLRenderer({ canvas: canvas, antialias: true });
        renderer.setSize(window.innerWidth, window.innerHeight);
        renderer.xr.enabled = true;

        scene = new THREE.Scene();
        scene.background = new THREE.Color(0x000000);

        cameraL = new THREE.PerspectiveCamera(75, 0.5, 0.1, 1000);
        cameraR = new THREE.PerspectiveCamera(75, 0.5, 0.1, 1000);
      }

      function removeStereoMeshes() {
        if (stereoMeshL) {
          scene.remove(stereoMeshL);
          stereoMeshL.geometry.dispose();
          stereoMeshL.material.dispose();
          stereoMeshL = null;
        }
        if (stereoMeshR) {
          scene.remove(stereoMeshR);
          stereoMeshR.geometry.dispose();
          stereoMeshR.material.dispose();
          stereoMeshR = null;
        }
        if (videoTexture) {
          videoTexture.dispose();
          videoTexture = null;
        }
      }

      function cleanupLayers() {
        xrReferenceSpace = null;
        xrMediaBinding = null;
        xrQuadLayer = null;
        xrProjectionLayer = null;
        xrGlContext = null;
      }

      async function enterVR() {
        if (!navigator.xr) {
          alert('WebXR is not supported on this device');
          return;
        }
        if (typeof XRMediaBinding === 'undefined') {
          alert('XRMediaBinding is not available in this browser');
          return;
        }
        if (!videoElement) {
          alert('Video stream not ready yet');
          return;
        }

        const supported = await navigator.xr.isSessionSupported('immersive-vr');
        if (!supported) {
          alert('Immersive VR not supported on this device');
          return;
        }

        try {
          xrSession = await navigator.xr.requestSession('immersive-vr', {
            optionalFeatures: ['local-floor', 'bounded-floor', 'layers']
          });
        } catch (e) {
          setStatus('Status: Failed to enter VR - ' + e.message);
          return;
        }

        renderer.setAnimationLoop(null);

        try {
          xrReferenceSpace = await xrSession.requestReferenceSpace('local-floor');
        } catch (e) {
          xrReferenceSpace = await xrSession.requestReferenceSpace('local');
        }

        xrMediaBinding = new XRMediaBinding(xrSession);
        await videoElement.play().catch(() => {});
        const readyForLayer = await waitForVideoReady(videoElement);
        if (!readyForLayer) {
          await xrSession.end();
          setStatus('Status: Video not ready for XR layer');
          return;
        }

        const width = videoElement.videoWidth || 3840;
        const height = videoElement.videoHeight || 1080;
        const safeWidth = width || 3840;
        const safeHeight = height || 1080;
        const eyeWidth = safeWidth / 2;
        const quadWidth = 4;
        const quadHeight = quadWidth * (safeHeight / eyeWidth);

        try {
          xrQuadLayer = xrMediaBinding.createQuadLayer(videoElement, {
            space: xrReferenceSpace,
            layout: 'stereo-left-right',
            width: quadWidth,
            height: quadHeight,
            transform: new XRRigidTransform({ z: -3, y: 1.4 })
          });
        } catch (e) {
          await xrSession.end();
          setStatus('Status: Failed to create XR layer - ' + e.message);
          return;
        }

        xrProjectionLayer = null;
        xrGlContext = null;
        if (typeof XRWebGLLayer !== 'undefined') {
          try {
            const glCanvas = document.createElement('canvas');
            const gl = glCanvas.getContext('webgl', { alpha: true, antialias: false });
            if (gl) {
              if (gl.makeXRCompatible) {
                await gl.makeXRCompatible();
              }
              xrGlContext = gl;
              xrProjectionLayer = new XRWebGLLayer(xrSession, gl);
            }
          } catch (err) {
            console.warn('Failed to create XRWebGLLayer', err);
            xrProjectionLayer = null;
            xrGlContext = null;
          }
        }

        const activeLayers = xrProjectionLayer ? [xrProjectionLayer, xrQuadLayer] : [xrQuadLayer];
        xrSession.updateRenderState({ layers: activeLayers });
        vrMode = true;
        vrModeType = 'layers';
        setStatus('Status: VR Stereo Beta Active (Layers API)');

        const onXRFrame = (time, frame) => {
          if (!xrSession || vrModeType !== 'layers') return;
          processControllerInput(xrSession);
          xrSession.requestAnimationFrame(onXRFrame);
        };
        xrSession.requestAnimationFrame(onXRFrame);

        xrSession.addEventListener('end', () => {
          vrMode = false;
          vrModeType = null;
          cleanupLayers();
          setStatus('Status: VR Mode Ended');
          xrSession = null;
          sendDrive(0, 0);
        });

      }

      // ステレオビデオメッシュ作成
      function createStereoVideoMesh() {
        if (!videoElement) return false;

        removeStereoMeshes();

        videoTexture = new THREE.VideoTexture(videoElement);
        videoTexture.minFilter = THREE.LinearFilter;
        videoTexture.magFilter = THREE.LinearFilter;

        const radius = 5;
        const geometry = new THREE.SphereGeometry(radius, 64, 32);
        geometry.scale(-1, 1, 1);

        const materialL = new THREE.ShaderMaterial({
          uniforms: { map: { value: videoTexture } },
          vertexShader: `
            varying vec2 vUv;
            void main() {
              vUv = uv;
              gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
            }
          `,
          fragmentShader: `
            uniform sampler2D map;
            varying vec2 vUv;
            void main() {
              vec2 uv = vec2(vUv.x * 0.5, vUv.y);
              gl_FragColor = texture2D(map, uv);
            }
          `,
          side: THREE.BackSide
        });

        const materialR = new THREE.ShaderMaterial({
          uniforms: { map: { value: videoTexture } },
          vertexShader: `
            varying vec2 vUv;
            void main() {
              vUv = uv;
              gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
            }
          `,
          fragmentShader: `
            uniform sampler2D map;
            varying vec2 vUv;
            void main() {
              vec2 uv = vec2(0.5 + vUv.x * 0.5, vUv.y);
              gl_FragColor = texture2D(map, uv);
            }
          `,
          side: THREE.BackSide
        });

        stereoMeshL = new THREE.Mesh(geometry.clone(), materialL);
        stereoMeshL.layers.set(1);
        scene.add(stereoMeshL);

        stereoMeshR = new THREE.Mesh(geometry.clone(), materialR);
        stereoMeshR.layers.set(2);
        scene.add(stereoMeshR);

        return true;
      }

      // コントローラー入力処理
      function processControllerInput(session) {
        if (!session) return;
        const now = performance.now();

        let throttle = 0;
        let steer = 0;
        let panDelta = 0;
        let tiltDelta = 0;
        let triggerPressed = false;

        // XR入力ソースからゲームパッド取得
        for (const source of session.inputSources) {
          if (!source.gamepad) continue;

          const gp = source.gamepad;
          const axes = gp.axes;
          const buttons = gp.buttons;

          // Questコントローラー: axes[2]=X, axes[3]=Y (thumbstick)
          // 左コントローラー: 走行操作（throttle + steer）
          if (source.handedness === 'left' && axes.length >= 4) {
            // Y軸（前後）- 上が負、下が正なので反転
            const y = -axes[3];
            if (Math.abs(y) > DEADZONE) {
              throttle = y;
            }
            // X軸（左右）- ステアリング
            const x = axes[2];
            if (Math.abs(x) > DEADZONE) {
              steer = x;
            }
          }

          // 右コントローラー: カメラ パン/チルト
          if (source.handedness === 'right' && axes.length >= 4) {
            // X軸 → パン（左右）
            const x = axes[2];
            if (Math.abs(x) > DEADZONE) {
              panDelta = x * 3;  // 感度調整
            }
            // Y軸 → チルト（上下）- 上が負なので反転
            const y = -axes[3];
            if (Math.abs(y) > DEADZONE) {
              tiltDelta = y * 2;  // 感度調整
            }
          }

          // トリガー（インデックス0が通常トリガー）で停止
          if (buttons.length > 0 && buttons[0].pressed) {
            triggerPressed = true;
          }
        }

        // トリガーで強制停止
        if (triggerPressed) {
          throttle = 0;
          steer = 0;
        }

        // 走行コマンド送信
        if (now - lastSendTime >= SEND_INTERVAL) {
          const driveChanged = Math.abs(throttle - lastThrottle) > 0.05 ||
                               Math.abs(steer - lastSteer) > 0.05;

          if (driveChanged || (throttle !== 0 || steer !== 0)) {
            sendDrive(
              Math.round(throttle * 100) / 100,
              Math.round(steer * 100) / 100
            );
            lastThrottle = throttle;
            lastSteer = steer;
            lastSendTime = now;
          }
        }

        // カメラ パン/チルト送信
        if (now - lastCameraSendTime >= SEND_INTERVAL) {
          if (Math.abs(panDelta) > 0 || Math.abs(tiltDelta) > 0) {
            // 現在値を更新（範囲制限付き）
            currentPan = Math.max(-90, Math.min(90, currentPan + panDelta));
            currentTilt = Math.max(-35, Math.min(65, currentTilt + tiltDelta));

            sendCamera(
              Math.round(currentPan),
              Math.round(currentTilt)
            );
            lastCameraSendTime = now;
          }
        }
      }

      // VRレンダリングループ
      function renderVR(timestamp, frame) {
        if (!frame) return;

        const session = renderer.xr.getSession();

        // コントローラー入力処理
        if (session && mqttClient && mqttClient.connected) {
          processControllerInput(session);
        }

        const pose = frame.getViewerPose(renderer.xr.getReferenceSpace());

        if (pose) {
          const glLayer = session.renderState.baseLayer;
          const gl = renderer.getContext();

          gl.bindFramebuffer(gl.FRAMEBUFFER, glLayer.framebuffer);

          for (const view of pose.views) {
            const viewport = glLayer.getViewport(view);
            gl.viewport(viewport.x, viewport.y, viewport.width, viewport.height);

            const eyeCamera = view.eye === 'left' ? cameraL : cameraR;
            eyeCamera.matrix.fromArray(view.transform.matrix);
            eyeCamera.projectionMatrix.fromArray(view.projectionMatrix);
            eyeCamera.matrixWorldNeedsUpdate = true;

            eyeCamera.layers.enable(view.eye === 'left' ? 1 : 2);
            eyeCamera.layers.disable(view.eye === 'left' ? 2 : 1);

            renderer.render(scene, eyeCamera);
          }
        }

        if (videoTexture) {
          videoTexture.needsUpdate = true;
        }
      }

      // 非VRプレビューモード
      function startPreview() {
        if (!videoElement) return;

        previewMode = true;
        setStatus('Status: Preview Mode (Non-VR)<br>Use arrow keys to control');
        preview.style.display = 'none';

        videoTexture = new THREE.VideoTexture(videoElement);
        videoTexture.minFilter = THREE.LinearFilter;
        videoTexture.magFilter = THREE.LinearFilter;

        const aspect = window.innerWidth / window.innerHeight;
        camera = new THREE.PerspectiveCamera(75, aspect, 0.1, 1000);
        camera.position.z = 2;

        const planeGeomL = new THREE.PlaneGeometry(1, 1);
        const materialL = new THREE.ShaderMaterial({
          uniforms: { map: { value: videoTexture } },
          vertexShader: `
            varying vec2 vUv;
            void main() {
              vUv = uv;
              gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
            }
          `,
          fragmentShader: `
            uniform sampler2D map;
            varying vec2 vUv;
            void main() {
              vec2 uv = vec2(vUv.x * 0.5, vUv.y);
              gl_FragColor = texture2D(map, uv);
            }
          `
        });
        const meshL = new THREE.Mesh(planeGeomL, materialL);
        meshL.position.x = -0.55;
        scene.add(meshL);

        const planeGeomR = new THREE.PlaneGeometry(1, 1);
        const materialR = new THREE.ShaderMaterial({
          uniforms: { map: { value: videoTexture } },
          vertexShader: `
            varying vec2 vUv;
            void main() {
              vUv = uv;
              gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
            }
          `,
          fragmentShader: `
            uniform sampler2D map;
            varying vec2 vUv;
            void main() {
              vec2 uv = vec2(0.5 + vUv.x * 0.5, vUv.y);
              gl_FragColor = texture2D(map, uv);
            }
          `
        });
        const meshR = new THREE.Mesh(planeGeomR, materialR);
        meshR.position.x = 0.55;
        scene.add(meshR);

        function animate() {
          if (!previewMode) return;
          requestAnimationFrame(animate);
          if (videoTexture) videoTexture.needsUpdate = true;
          renderer.render(scene, camera);
        }
        animate();

        previewBtn.disabled = true;
      }

      // キーボード操作（非VR用）
      window.addEventListener('keydown', (e) => {
        if (!mqttClient || !mqttClient.connected) return;

        const speed = 0.5;
        switch (e.code) {
          case 'ArrowUp':
            sendDrive(speed, 0);
            e.preventDefault();
            break;
          case 'ArrowDown':
            sendDrive(-speed, 0);
            e.preventDefault();
            break;
          case 'ArrowLeft':
            sendDrive(speed, -1);
            e.preventDefault();
            break;
          case 'ArrowRight':
            sendDrive(speed, 1);
            e.preventDefault();
            break;
          case 'Space':
            sendDrive(0, 0);
            e.preventDefault();
            break;
        }
      });

      // カメラ配信のON/OFF
      async function toggleCamera() {
        if (!room) return;

        try {
          if (!cameraEnabled) {
            // カメラをONにする
            const stream = await navigator.mediaDevices.getUserMedia({
              video: { width: 640, height: 480, facingMode: 'user' }
            });
            const videoTrack = stream.getVideoTracks()[0];
            localVideoTrack = new LivekitClient.LocalVideoTrack(videoTrack);
            await room.localParticipant.publishTrack(localVideoTrack);

            // ローカルプレビュー表示
            localPreview.srcObject = stream;
            localPreview.style.display = 'block';

            cameraEnabled = true;
            cameraBtn.textContent = 'Camera ON';
            cameraBtn.classList.add('active');
            console.log('Camera published');
          } else {
            // カメラをOFFにする
            if (localVideoTrack) {
              await room.localParticipant.unpublishTrack(localVideoTrack);
              localVideoTrack.stop();
              localVideoTrack = null;
            }
            localPreview.srcObject = null;
            localPreview.style.display = 'none';

            cameraEnabled = false;
            cameraBtn.textContent = 'Camera OFF';
            cameraBtn.classList.remove('active');
            console.log('Camera unpublished');
          }
        } catch (e) {
          console.error('Camera toggle error:', e);
          setStatus('Status: Camera error - ' + e.message);
        }
      }

      // マイク配信のON/OFF
      async function toggleMic() {
        if (!room) return;

        try {
          if (!micEnabled) {
            // マイクをONにする
            const stream = await navigator.mediaDevices.getUserMedia({
              audio: true
            });
            const audioTrack = stream.getAudioTracks()[0];
            localAudioTrack = new LivekitClient.LocalAudioTrack(audioTrack);
            await room.localParticipant.publishTrack(localAudioTrack);

            // マイクレベルメーターをセットアップ
            setupMicAnalyser(stream);

            micEnabled = true;
            micBtn.textContent = 'Mic ON';
            micBtn.classList.add('active');
            console.log('Mic published');
          } else {
            // マイクをOFFにする
            if (localAudioTrack) {
              await room.localParticipant.unpublishTrack(localAudioTrack);
              localAudioTrack.stop();
              localAudioTrack = null;
            }

            // マイクレベルメーターを停止
            stopMicMeter();

            micEnabled = false;
            micBtn.textContent = 'Mic OFF';
            micBtn.classList.remove('active');
            console.log('Mic unpublished');
          }
        } catch (e) {
          console.error('Mic toggle error:', e);
          setStatus('Status: Mic error - ' + e.message);
        }
      }

      // イベントリスナー
      connectBtn.addEventListener('click', connect);
      vrBtn.addEventListener('click', enterVR);
      previewBtn.addEventListener('click', startPreview);
      cameraBtn.addEventListener('click', toggleCamera);
      micBtn.addEventListener('click', toggleMic);

      // 初期化
      initThreeJS();

      // リサイズ対応
      window.addEventListener('resize', () => {
        renderer.setSize(window.innerWidth, window.innerHeight);
      });
    </script>
  </body>
</html>
